{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 Quiz\n",
    "\n",
    "## Name - UNI\n",
    "\n",
    "### Due Tues. Nov 15th 11:59pm\n",
    "\n",
    "In this quiz, we're going to load documents from 2 categories (space, cars) in the 20newsgroups dataset. The goal is to train a classifier that classifies documents into these 2 categories based on a term frequency representation of the documents. We will then calculate mean cross-validaion accuracy of a RandomForestClassifier using this transformation.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Replace the Name and UNI in cell above and the notebook filename\n",
    "\n",
    "Replace all '____' below using the instructions provided.\n",
    "\n",
    "When completed, \n",
    " 1. make sure you've replaced Name and UNI in the first cell and filename\n",
    " 2. Kernel -> Restart & Run All to run all cells in order \n",
    " 3. Print Preview -> Print (Landscape Layout) -> Save to pdf \n",
    " 4. post pdf to GradeScope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fetch_20newsgroups from sklearn.datasets\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load the dataset using fetch_20newsgroups().\n",
    "#   Only fetch the two categories of interest using categories=['sci.space','rec.autos']\n",
    "# Store in the result into newsgroups\n",
    "newsgroups = fetch_20newsgroups(categories=['sci.space','rec.autos'])\n",
    "\n",
    "# Store the newsgroups.data as docs, newsgroups.target as y and newsgroups.target_names as y_names\n",
    "docs = newsgroups.data\n",
    "y = newsgroups.target\n",
    "y_names = newsgroups.target_names\n",
    "\n",
    "# Print the number of observations by printing the length of docs\n",
    "#  You should get 1187\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the text of the first document in docs.\n",
    "# Note: try printing both with and without the print() statement\n",
    "#  with the print statement, linebreaks are parsed,\n",
    "#  without, linebreaks are printed as excape characters\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the target value of the first document in y.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the target_name of the first document using y_names and y.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CountVectorizer to Convert To TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer from sklearn\n",
    "____\n",
    "\n",
    "# Initialize a CountVectorizer object. It should\n",
    "#   lowercase all text, \n",
    "#   include both unigrams and bigrams: ngram_range=(1,2)\n",
    "#   exclude terms that occur in fewer than 10 documents: min_df=10\n",
    "#   exclude terms that occur in more than 95% of documents: max_df=.95\n",
    "# Store as cvect\n",
    "____\n",
    "\n",
    "# Fit cvect on docs and transform docs into their term frequency representation.\n",
    "# Store as X_tf\n",
    "____\n",
    "\n",
    "# Print the shape of X_tf. \n",
    "# The number of rows should match the number of documents above\n",
    "#  and the number of columns should be near 6000\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the last 5 terms in the learned vocabulary in cvect\n",
    "#   using .get_feature_names_out() which returns a list of terms corresponding\n",
    "#   to the order of the columns in X_tf\n",
    "# They should all be related to zoos or zoology\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stopwords learned by cvect are stored as a set in cvect.stop_words_\n",
    "# We'd like to print out a small subset of these terms.\n",
    "# One way to get a subset of a set is to treat it as a list.\n",
    "# First, convert the stop_words_ set to a list.\n",
    "# Store as stop_words_list\n",
    "____\n",
    "\n",
    "# Print out the first 5 elements in stop_words_list.\n",
    "# Note that, since a set is unordered, \n",
    "#  there is no meaning to the ordering of these terms and they may vary over runs.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Mean CV Accuracy Using RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cross_val_score from sklearn\n",
    "____\n",
    "\n",
    "# Import RandomForestClassifier from sklearn\n",
    "____\n",
    "\n",
    "# Get a set of 5-fold CV scores using\n",
    "#  a RandomForestClassifier \n",
    "#   with 50 trees \n",
    "#   and n_jobs=-1 all other settings default\n",
    "#   and the full dataset X_tf and y\n",
    "# Store as cv_scores\n",
    "____\n",
    "\n",
    "# Print the mean of these cv_scores rounded to a precision of 2.\n",
    "#  The mean accuracy should be above .9\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Find Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer stores the feature names (terms in the vocabulary) in two ways:\n",
    "#  1. as a dictionary of term:colum_index pairs, accessed via cvect.vocabulary_\n",
    "#  2. as a list of terms, in column index order, accessed via cvect.get_feature_names_out()\n",
    "#\n",
    "# We can get the indices of the most important features by training a new RandomForestClassifier on X_tf,y\n",
    "#  and accessing .feature_importances_\n",
    "#\n",
    "# Using some combination of the above data-structures, \n",
    "#  print out the top 10 terms in the vocabulary\n",
    "#  ranked by the feature importances learned by a RandomForestClassifier with 50 trees\n",
    "# \n",
    "# The terms you find will likely not be surprising given the document categories.\n",
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-f22",
   "language": "python",
   "name": "eods-f22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
